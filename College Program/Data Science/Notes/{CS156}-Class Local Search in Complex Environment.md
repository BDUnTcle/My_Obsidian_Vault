---
create date: 2024-09-11
tags:
  - 我的研究生
  - DataSince
  - SJSU
  - review
modification date: 
type: CourseNotes
---

# Before the Class
## Lectures and Materials
---
# Review List
>[! abstract] Main Topics
>1. Local Search algorithms
>	1. Know the basic idea of how local search works
>	2. Know the advantages of local search
>	3. Know what is "global maximum" and "global minimum", and when use which one
>2. Hill-Climbing Search
>	1. Know the idea of hill climbing
>	2. Know 3 optimization of hill climbing: [[#Stochastic hill climbing]], [[#First-choice hill climbing]], [[#Random-restart hill climbing]]
>3. know [[#Simulated annealing]]
>	1. know basic idea of simulated annealing and why need it，how it different from hill-climbing
>	2. Understand the pseudo code for it
>4. [[#Local beam search]] & [[#Genetic Algorithms]]

---
# In-Class Problems
>[!tip] idea behind local search
>Local search algorithms operate using a single current node (rather than multiple paths) and generally move only to neighbors of that node
>>[!cite] 2 advantages
>>1. Use very little memory--usually a constant amount
>>2. Can often find reasonable solutions in large or infinite state spaces

![[Artificial Intelligence - A Modern Approach (3rd Edition).pdf#page=140&rect=148,151,552,391|Artificial Intelligence - A Modern Approach (3rd Edition), p.121]]
- **global maximum**:
	- @ if elevation corresponds to **object function**, then we want to get the peak
- **global minimum**
	- @ if elevation corresponds to **cost**, then we want to get the lowest valley
## Hill Climbing
- Gradient ascent/descent
![[Artificial Intelligence - A Modern Approach (3rd Edition).pdf#page=141&rect=122,537,527,696|Artificial Intelligence - A Modern Approach (3rd Edition), p.122]]
- **Completeness**: No
### Stochastic hill climbing
- @ choose at random from among the uphill moves; the probability of selection can vary with the steepness of the uphill move
### First-choice hill climbing
- @ generate successors randomly until one is generated that is better than the current state
### Random-restart hill climbing
- @ conduct a series of hill climbing searches from randomly generated initial states until a goal is found
## Simulated annealing
- @ In simulated annealing， some "**bad steps**" are *allowed*. However, its probability will decrease exponentially through time going by

>[!tip] How could combine hill climbing with random walk to make it both efficiency and completeness?
>> [!PDF|important] [[Artificial Intelligence - A Modern Approach (3rd Edition).pdf#page=144&selection=54,0,57,62&color=important|Artificial Intelligence - A Modern Approach (3rd Edition), p.125]]
> >image the task of getting a ping-pong ball into the deepest crevice in a bumpy surface. If we just let the ball roll, it will come to rest at a local minimum. If we shake the surface, we can bounce the ball out of the local minimum. The trick is to shake just hard enough to bounce the ball out of local minima but not hard enough to dislodge it from the global minimum

![[Artificial Intelligence - A Modern Approach (3rd Edition).pdf#page=145&rect=123,478,526,697&color=important|Artificial Intelligence - A Modern Approach (3rd Edition), p.126]]
- ~ instead of picking the *best move*, it picks a **random move**
- ~ if the move improves the situation, it will be accepted
- ~ if it is getting worse, the algorithm accepts the move with a probability $p<1$. This p decrease exponentially with the "badness" of the move $\triangle E$ and with the temperature goes down
- ~ "bad moves" are more likely to be allowed at the start when T is high and become more unlikely as T decreases.

---
## Local beam search
>[!tip] Rather than only keep 1 state in memory, keep $k$ states
>> - at each step, all the successors of all k states are generated
>> - if any one is a goal, the algorithm halts, otherwise, it selects the k best successors from the list and repeats
## Genetic Algorithms
>[!tip] What is stochastic beam search?
>Choose the successors at random
> ![[Artificial Intelligence - A Modern Approach (3rd Edition).pdf#page=145&rect=57,203,531,288&color=important|Artificial Intelligence - A Modern Approach (3rd Edition), p.126]]

- @ in GA, successor states are generated by combing 2 parent states
![[Artificial Intelligence - A Modern Approach (3rd Edition).pdf#page=146&rect=148,525,551,703&color=important|Artificial Intelligence - A Modern Approach (3rd Edition), p.127]]
---

# Flash Cards
#flashcards/EnglishLearning 
 Metallurgy ---> 冶金学
 Annealing ---> 给(金属，玻璃)退火
 crevice ---> 裂缝；(岩石或墙壁的)裂隙；裂口
 bumpy ---> 不平的