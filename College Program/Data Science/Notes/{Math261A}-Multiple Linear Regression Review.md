---
create date: 2024-09-11
tags:
  - 我的研究生
  - DataSince
  - SJSU
  - review
modification date: 
type: CourseNotes
---

# Before the Class
## Lectures and Materials
- [[{Math261A}-Class 6]]
- [[{Math261A}-Class 7]]
- [[{Math261A}-Class 8 Prediction, multicollinearity]]
---
# Review List
>[! abstract] Main Topics
>1. Manipulate small vectors and matrices by hand. Compute sums, differences, products, transposes, inverses and determinants of small matrices. Find estimates of least squares parameters in vector form
>2. Understand the two di erent representations of regression data (as k+1 vectors in n-dimensional space or as n vectors in (k+1)-dimensional space)
>3. Interpret R output for multiple regression models: read o intercept, slope, residual variance estimates; read o results of hypothesis tests for the slopes, test for signi cance of regression, R2, adjusted R2
>4. Be able to show that least squares parameter estimates are unbiased and derive covariance matrix of ${\beta}$
>5. Conduct hypothesis tests and compute condence intervals for individ ual slopes and for signi cance of regression by-hand given summary statistics
>6. Carry our tests for groups of predictors using summary statistics or R output
>7. Understand what simultaneous confidence intervals are and how to construct them in the two-predictor scenario
>8. Condence intervals for the mean response at a given predictor level
>9. Prediction interval for a new observation at a given predictor level
>10. Know what multicollinearity is and what effect the presence of multicollinearity has on a regression analysis
>11. Know what variance in ation factors are and how they help us to tell whether there is multicollinearity

---
# In-Class Problems

---

# Flash Cards
